{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNV15zG8mX1RGNP7cnCSOL2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Build the Neural Network\n","Neural networks comprise of layers/modules that perform operations on data. The torch.nn namespace provides all the building blocks you need to build your own neural network. Every module in PyTorch subclasses the nn.Module. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily.\n","\n","https://pytorch.org/docs/stable/nn.html"],"metadata":{"id":"uuEQPVbkZU77"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"emI2JFCHYnMY","executionInfo":{"status":"ok","timestamp":1736700346211,"user_tz":-300,"elapsed":11687,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}}},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"code","source":["# We want to be able to train our model on a hardware accelerator like the GPU or MPS, if available. Let’s check to see if torch.cuda or torch.backends.mps are available, otherwise we use the CPU.\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZhONVVyZi7g","executionInfo":{"status":"ok","timestamp":1736700346211,"user_tz":-300,"elapsed":3,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"02a8720d-0d0b-4f5a-e601-e7b32d00df56"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","source":["# We define our neural network by subclassing nn.Module, and initialize the neural network layers in __init__.\n","# Every nn.Module subclass implements the operations on input data in the forward method.\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"],"metadata":{"id":"8T5anGcTZi4H","executionInfo":{"status":"ok","timestamp":1736700429007,"user_tz":-300,"elapsed":443,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# We create an instance of NeuralNetwork, and move it to the device, and print its structure.\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-dGAhrXZi1C","executionInfo":{"status":"ok","timestamp":1736700517983,"user_tz":-300,"elapsed":465,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"e2532e5a-1fb5-448a-dff0-7b35442797af"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["To use the model, we pass it the input data. This executes the model’s forward, along with some background operations. Do not call model.forward() directly!\n","\n","Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the nn.Softmax module."],"metadata":{"id":"kHCS_jlfa1de"}},{"cell_type":"code","source":["X = torch.rand(1, 28, 28, device=device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LW6v-oGNZixG","executionInfo":{"status":"ok","timestamp":1736700667978,"user_tz":-300,"elapsed":594,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"a385ef1f-5f4c-4e50-af45-2ca91023ff46"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: tensor([6], device='cuda:0')\n"]}]},{"cell_type":"code","source":["input_image = torch.rand(3,28,28)\n","print(input_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_MEpPWeZitb","executionInfo":{"status":"ok","timestamp":1736700719547,"user_tz":-300,"elapsed":1094,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"43d7aeb8-e729-45e4-8c1a-4129baf677a8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 28, 28])\n"]}]},{"cell_type":"code","source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czBuzh4Wbgo1","executionInfo":{"status":"ok","timestamp":1736700748897,"user_tz":-300,"elapsed":3,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"8dd2ea00-737c-44fb-e12a-afed6b9f4807"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 784])\n"]}]},{"cell_type":"code","source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDKEVtUxbglL","executionInfo":{"status":"ok","timestamp":1736700763487,"user_tz":-300,"elapsed":3,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"49ae1bdf-3a7f-4dff-90bc-7a17864eedd6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n"]}]},{"cell_type":"code","source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGb-ZbRzbgiS","executionInfo":{"status":"ok","timestamp":1736700774555,"user_tz":-300,"elapsed":472,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"5fa07241-9b01-46b3-d37f-8b26e82cfd92"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Before ReLU: tensor([[ 0.0143, -0.2359,  0.0525, -0.0214,  0.4823,  0.2760,  0.1851,  0.2280,\n","          0.1425, -0.0992,  0.3416,  0.0462,  0.6495,  0.5614, -0.2581, -0.1326,\n","          0.0017, -0.0579,  0.2432,  0.0779],\n","        [-0.1947, -0.0913,  0.0550, -0.1470,  0.1089,  0.1861, -0.2263, -0.0049,\n","          0.1185,  0.3399, -0.0331,  0.1278,  0.5208,  0.7294, -0.1233, -0.0622,\n","         -0.1389, -0.0708,  0.2300,  0.0874],\n","        [-0.3029, -0.4159,  0.3804, -0.0134,  0.3444,  0.3588, -0.0566, -0.1722,\n","          0.1317, -0.1892,  0.0775,  0.0936,  0.5782,  0.6789, -0.2446, -0.2956,\n","         -0.3691,  0.1763, -0.1797, -0.0143]], grad_fn=<AddmmBackward0>)\n","\n","\n","After ReLU: tensor([[0.0143, 0.0000, 0.0525, 0.0000, 0.4823, 0.2760, 0.1851, 0.2280, 0.1425,\n","         0.0000, 0.3416, 0.0462, 0.6495, 0.5614, 0.0000, 0.0000, 0.0017, 0.0000,\n","         0.2432, 0.0779],\n","        [0.0000, 0.0000, 0.0550, 0.0000, 0.1089, 0.1861, 0.0000, 0.0000, 0.1185,\n","         0.3399, 0.0000, 0.1278, 0.5208, 0.7294, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.2300, 0.0874],\n","        [0.0000, 0.0000, 0.3804, 0.0000, 0.3444, 0.3588, 0.0000, 0.0000, 0.1317,\n","         0.0000, 0.0775, 0.0936, 0.5782, 0.6789, 0.0000, 0.0000, 0.0000, 0.1763,\n","         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"]}]},{"cell_type":"code","source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)"],"metadata":{"id":"QxwwZ8zkbgfK","executionInfo":{"status":"ok","timestamp":1736700787220,"user_tz":-300,"elapsed":1003,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"],"metadata":{"id":"pqb588w0bgbz","executionInfo":{"status":"ok","timestamp":1736700798273,"user_tz":-300,"elapsed":477,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(f\"Model structure: {model}\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b01q_t-ubgY5","executionInfo":{"status":"ok","timestamp":1736700809078,"user_tz":-300,"elapsed":942,"user":{"displayName":"Коnstаntin К.","userId":"13287625575777041425"}},"outputId":"d0dadaf4-1338-4483-ead2-456a8572fcfe"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0353,  0.0302, -0.0036,  ..., -0.0353, -0.0071,  0.0280],\n","        [ 0.0072, -0.0201,  0.0233,  ...,  0.0237, -0.0261, -0.0103]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0133, -0.0068], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0129, -0.0094, -0.0078,  ..., -0.0091, -0.0283,  0.0254],\n","        [ 0.0154,  0.0124,  0.0376,  ...,  0.0135, -0.0342,  0.0360]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0262, -0.0139], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0223, -0.0368,  0.0075,  ...,  0.0401,  0.0072, -0.0303],\n","        [ 0.0185, -0.0319,  0.0283,  ..., -0.0096,  0.0424,  0.0381]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0084, -0.0228], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wc8PnCo4bgVy"},"execution_count":null,"outputs":[]}]}